[FILE_SETTINGS]
#inputfile = hdfs://localhost:9000/input/Sample.csv
inputfile = file:///home/hadoop/superstore1.csv
#result_file = hdfs://localhost:9000/sample_test_result
result_file = file:///home/hadoop/superstore1_meta

[COLUMN_SETTINGS]
#consider_columns = column1, column2, column3, col1, col2
#measure_suggestions = col1, col2
consider_columns= Row ID,Order ID,Order Date,Order Priority,Order Quantity,Sales, Region

[DATE_SETTINGS]

[DIMENSION_FILTER]
#dim_col1 = level1, level2, level3, level8
#dim_col2 = L1, L4, L0
Region = Central, South, East
Order Priority = Low, High

[MEASURE_FILTER]
#num_col1 = 10,100
#num_col2 = -192.28,20918.219
Row ID = 100,2000
Sales = 200,5000

[DATE_FILTER]
